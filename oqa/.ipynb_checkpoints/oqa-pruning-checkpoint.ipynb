{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b986ac5-1a73-4968-b4e3-d3572784bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import pickle\n",
    "import transformer_lens\n",
    "from torch.optim import AdamW\n",
    "from os.path import join\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_from_disk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/leiyu/projects/def-yangxu/leiyu/circuit-discovery')\n",
    "from dmc.circuit_gpt import *\n",
    "from oqa_dataset import *\n",
    "from oqa_utils import *\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d04f1-6f27-4ab2-972b-2cd347f00c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "048cc430-d52c-4cc0-9330-7eebe6b2c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DiffMaskArgs:\n",
    "    model_dir: str = '/home/leiyu/projects/def-yangxu/leiyu/LMs/'\n",
    "    data_dir: str = '/home/leiyu/projects/def-yangxu/leiyu/circuit-discovery/data/'\n",
    "    results_dir: str = '/home/leiyu/scratch/circuit-discovery/mask_logits/'\n",
    "    data_name: str = 'pararel_data_all.json'\n",
    "    pararel_rel_ids: str = 'P36 P1376'\n",
    "    model_name: str = 'gpt2-small'\n",
    "    gs_temp_weight: float = 0.01\n",
    "    gs_temp_edge: float = 1.0\n",
    "    logits_w_init: float = 0.0\n",
    "    logits_e_init: float = 0.0\n",
    "    test_ratio: float = 0.2\n",
    "    batch_size: int = 16\n",
    "    train_epochs_weight: int = 1000\n",
    "    train_epochs_edge: int = 50\n",
    "    lr_weight: float = 0.1\n",
    "    lr_edge: float = 0.1\n",
    "    lambda_sparse_weight_init: float = 1.\n",
    "    lambda_sparse_edge_init: float = 1.\n",
    "    lambda_complete_weight_init: float = 1.\n",
    "    lambda_complete_edge_init: float = 1.\n",
    "    save_every: int = 5\n",
    "    resume_epoch_w: int = 0\n",
    "    resume_epoch_e: int = 0\n",
    "    use_weight_masks: bool = False\n",
    "    n_epoch_warmup_lambda_sparse: int = 20\n",
    "    n_epoch_cooldown_lambda_sparse: int = 20\n",
    "    max_times_lambda_sparse: float = 100.\n",
    "    min_times_lambda_sparse: float = 0.01\n",
    "    random_seed: int = 0\n",
    "\n",
    "args = DiffMaskArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46b645d1-5262-4b5f-8d74-301d7cee0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path that stores gpt-small weights and gpt tokenizer\n",
    "model_path = join(args.model_dir, args.model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b78c39d-3580-4eb3-9c8e-7d40be99682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load OQA data\n",
    "ds_dict = pickle.load(open(join(args.data_dir, 'pararel_capital_ds_dict.p'), 'rb'))\n",
    "full_model_target_log_probs = torch.load(f'full_model_results/target_log_probs.pt')\n",
    "full_model_pred_labels = torch.load(f'full_model_results/pred_labels.pt')\n",
    "capital_vocab_idx = torch.load(f'full_model_results/capital_vocab_idx.pt')\n",
    "ds_dict['full_model_target_log_probs'] = full_model_target_log_probs\n",
    "ds_dict['full_model_pred_labels'] = full_model_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dcf7f62-bf9c-4a15-b09b-221af2e2373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = OQACircuitDataset(ds_dict)\n",
    "n_train = int(0.8*len(ds))\n",
    "n_test = len(ds) - n_train\n",
    "ds_train, ds_test = torch.utils.data.random_split(ds, [n_train, n_test])\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=args.batch_size\n",
    ")\n",
    "eval_dl = DataLoader(\n",
    "    ds_test,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97e62149-5742-4171-b0ae-f373abca473d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'The capital of Haakon County is',\n",
       " 'label': 50,\n",
       " 'full_model_target_log_probs': tensor([ -7.3468,  -8.0343,  -8.5534,  -7.9324,  -8.0947,  -5.9757,  -7.2039,\n",
       "          -7.4835, -11.2138,  -7.4869,  -8.5819, -11.5449, -10.1456,  -6.6759,\n",
       "         -10.7692,  -7.7960,  -6.8112,  -4.9924,  -7.5453,  -6.9843, -10.4148,\n",
       "          -6.4187,  -8.2486,  -8.9324,  -8.5128,  -9.5808,  -7.5216,  -4.2317,\n",
       "          -5.4716,  -8.9545,  -8.1433,  -6.6596,  -6.7450,  -6.4809,  -8.7846,\n",
       "          -8.3562,  -5.6886,  -6.8378,  -9.1335,  -6.4357,  -6.2878,  -7.6560,\n",
       "         -10.1810, -10.6336, -10.5368,  -4.8770,  -6.7504,  -2.9278,  -9.5715,\n",
       "          -9.0878,  -9.5661,  -8.2746,  -4.8770,  -9.5494,  -7.3597,  -9.1926,\n",
       "          -4.2638, -11.3434,  -8.7225,  -4.2638,  -6.4417,  -8.4388, -10.9134,\n",
       "         -10.2426,  -4.2317,  -7.2723,  -7.9848, -11.0620,  -8.7507,  -8.4591,\n",
       "          -9.7536,  -8.8494,  -7.1412,  -8.3157,  -8.1154, -11.4140,  -8.4836,\n",
       "         -13.1069,  -7.5587,  -6.8248,  -8.8346,  -8.3776,  -4.5021,  -8.4672,\n",
       "          -9.8442,  -5.6909,  -7.0062,  -3.6914,  -6.6265,  -5.9195,  -9.0912,\n",
       "          -5.4780,  -8.7954,  -7.7059,  -7.7881,  -8.1256,  -7.6647,  -4.6220,\n",
       "          -7.6127, -10.2452,  -8.5637, -10.2538,  -9.1794,  -7.3084,  -7.8583,\n",
       "          -8.2654,  -9.0074, -11.4249,  -9.2750,  -4.2317,  -7.8232,  -6.4219,\n",
       "          -7.5881,  -6.6318,  -9.4161,  -9.8607,  -8.3353,  -8.0946,  -4.2317,\n",
       "          -9.7330,  -8.4002,  -8.1840,  -8.6935,  -9.3985,  -7.8510,  -6.4353,\n",
       "          -9.8486,  -7.6430,  -7.6508,  -7.5213,  -7.7046,  -7.7443,  -4.4970,\n",
       "          -7.3672,  -9.1223,  -4.0477,  -7.9863,  -7.1953,  -9.4471, -10.2059,\n",
       "          -7.8768,  -6.0402,  -8.1341,  -8.6579,  -8.0355,  -8.6093,  -7.4980,\n",
       "          -6.7375,  -9.1682, -10.1559,  -6.5881,  -9.6835, -10.4637,  -7.2993,\n",
       "          -9.3592,  -8.4602,  -6.5421,  -7.6416,  -7.3100,  -7.4222,  -8.9253,\n",
       "          -8.4922,  -9.6223,  -5.7996, -11.1955,  -4.8355,  -8.5842,  -8.3042,\n",
       "         -11.9935,  -7.9354,  -8.0495,  -8.9685,  -9.6231,  -9.2799,  -8.3284,\n",
       "          -8.0555,  -7.7543,  -9.2874,  -8.4974,  -8.9387,  -8.9996,  -7.2680,\n",
       "          -4.9753,  -6.7661,  -5.5605,  -9.9144,  -7.3808,  -4.2191,  -7.5349,\n",
       "          -7.5489,  -7.9283,  -7.8531,  -7.9221,  -9.4796,  -4.2154, -10.3838,\n",
       "          -5.8783,  -8.0001,  -6.2521,  -9.3055,  -4.0707,  -7.0134,  -9.1595,\n",
       "         -12.3077, -10.1358, -11.3430,  -8.8726,  -7.1329,  -6.4003,  -8.4000,\n",
       "          -9.9078,  -6.2866,  -8.3629,  -6.7550,  -7.8065,  -7.4351,  -7.5019,\n",
       "          -9.2423,  -6.8598,  -6.9042,  -8.2325,  -9.0464,  -4.9753,  -6.3930,\n",
       "          -8.2427,  -8.3883,  -6.3010,  -8.3879,  -7.2666,  -9.2509,  -8.1912,\n",
       "          -5.1530,  -8.3828,  -6.6215,  -8.2140,  -5.3463,  -7.3615,  -9.3125,\n",
       "          -7.6477,  -8.0917,  -8.5043, -10.0448,  -6.9507,  -8.7873,  -8.2913,\n",
       "          -7.8904,  -8.5840,  -6.7553,  -8.9314,  -6.3054,  -6.9035,  -6.9973,\n",
       "          -8.9045,  -6.4607,  -6.8619,  -8.9668,  -8.7483, -10.0220,  -7.0745,\n",
       "          -8.7521,  -6.0234,  -7.0372,  -8.0474,  -5.1996,  -9.7230,  -7.7360,\n",
       "          -8.1949,  -7.8728,  -7.1652,  -5.3344,  -8.3376,  -9.9913,  -4.9127,\n",
       "          -9.3439,  -8.7602,  -6.5993,  -6.8869,  -7.5782,  -6.6982,  -7.1457,\n",
       "          -6.9850,  -7.4139,  -8.3639,  -7.4916,  -5.5916,  -9.5676,  -8.0616,\n",
       "          -8.7764,  -7.5490,  -8.5557,  -8.4464,  -8.1606, -10.4409,  -6.2685,\n",
       "          -9.7427,  -7.1330,  -7.8364,  -6.5126,  -8.9862,  -4.5275,  -8.1680,\n",
       "          -8.4403,  -7.7065,  -7.4892,  -8.7213,  -7.2993,  -8.8016,  -6.8749,\n",
       "          -9.1654,  -9.8847,  -5.2904,  -9.8972,  -7.4665,  -7.1341,  -7.5009,\n",
       "          -6.4697,  -6.0397,  -5.7784,  -8.0553,  -8.6215,  -7.5748,  -7.1302,\n",
       "          -6.1852,  -5.1975,  -7.3021,  -7.8215,  -4.8763,  -7.3703,  -9.0012,\n",
       "          -4.3039,  -4.6220,  -8.0141,  -7.3503,  -5.6250,  -8.9220,  -6.5272,\n",
       "          -8.8485, -10.8238,  -5.8590,  -9.3374,  -6.9778,  -8.1741,  -8.6385,\n",
       "          -7.0976,  -7.7684,  -8.9986,  -7.0343,  -9.4649,  -8.1804,  -7.8497,\n",
       "          -7.5284,  -7.1849,  -9.3719,  -9.0092,  -8.8400,  -8.3697,  -8.5275,\n",
       "          -6.9042, -11.1973,  -4.5842,  -7.1392, -11.2172, -10.2349,  -7.4433,\n",
       "          -6.4462,  -7.3740,  -8.7048,  -7.5872,  -6.2179,  -7.5469,  -5.3341,\n",
       "          -7.0304,  -6.4265,  -7.7203, -10.9171,  -7.8718,  -8.5928,  -8.1816,\n",
       "          -4.3059, -10.1779,  -8.1660,  -8.9460,  -2.9278,  -9.8713, -11.3867,\n",
       "          -8.1284,  -9.4261,  -9.1849, -10.0056,  -7.6412,  -8.5865,  -8.8178,\n",
       "         -13.5549,  -6.9850,  -9.1275,  -8.0176,  -8.9363,  -7.7492,  -9.6615,\n",
       "          -7.6422,  -7.8388, -10.3025, -10.3953,  -8.1067,  -8.9030,  -9.2789,\n",
       "         -10.0845,  -8.0630,  -6.8112,  -7.5274,  -5.8994,  -5.4433,  -9.7011,\n",
       "         -10.1067,  -9.5788,  -7.7896,  -5.7178,  -8.0775,  -5.4433, -10.2064,\n",
       "          -9.3559,  -6.9875,  -5.1618,  -9.1461, -10.0745,  -8.4509,  -7.8248,\n",
       "          -8.3017,  -7.8893,  -7.0313,  -8.5058,  -9.4607,  -2.9278,  -4.2317,\n",
       "          -6.6113,  -7.1166,  -8.6883,  -9.1241,  -6.8096, -10.3618,  -8.3903,\n",
       "          -9.7994,  -7.8689,  -8.3074,  -6.3689,  -9.4573,  -6.4467,  -7.5665,\n",
       "          -9.3195,  -4.9753,  -6.5809,  -7.9715,  -8.1544,  -8.9071,  -7.0231,\n",
       "          -8.2301,  -6.6574, -10.1585,  -6.5385,  -8.2224,  -8.2023,  -9.6274,\n",
       "          -8.7888,  -8.8823,  -8.2575,  -8.9364,  -4.9312,  -7.5550,  -6.6748,\n",
       "          -7.1235,  -8.0091,  -7.9478,  -6.7106,  -7.5940,  -7.9769,  -6.9127,\n",
       "          -9.5367,  -7.5837,  -7.0764,  -7.2342,  -9.8364,  -5.5858,  -8.5975,\n",
       "          -8.7252,  -8.4454,  -5.5670,  -7.7777,  -9.3613,  -7.5762,  -7.3360,\n",
       "          -4.9127,  -8.1431, -12.1750,  -7.2181, -10.7716,  -7.3229,  -8.2572,\n",
       "          -7.3254,  -9.6094,  -9.1024,  -9.5245,  -8.2941,  -5.4716,  -4.5842,\n",
       "          -5.8516,  -9.1794,  -6.4397,  -8.1684,  -9.0935,  -7.2775, -10.9966,\n",
       "          -4.2638,  -8.4030, -10.4260,  -7.1873,  -9.1456,  -7.9224,  -7.8317,\n",
       "          -6.3754,  -8.6721,  -5.9238, -10.0436,  -9.2343,  -8.3439,  -7.2251,\n",
       "          -5.9423,  -6.6860,  -7.6462,  -8.0106, -10.0423,  -7.1432,  -8.2967,\n",
       "          -8.8714,  -7.5116,  -6.5747,  -8.7004,  -9.8591,  -8.1832,  -8.8641,\n",
       "          -6.4669,  -4.5275,  -9.4244,  -7.7043,  -3.6914,  -8.2486,  -5.6250,\n",
       "          -7.8241,  -9.5378,  -8.8488,  -8.8167,  -4.9127,  -6.0453,  -6.4551,\n",
       "          -7.9007,  -9.1655,  -6.7177,  -8.7678,  -6.0202,  -4.2191,  -6.3078,\n",
       "          -6.2366,  -6.9984,  -4.8785,  -8.5668,  -8.8266,  -7.4509,  -5.4287,\n",
       "          -5.6182,  -9.2130,  -7.2968,  -8.3276, -11.1453,  -8.6765,  -9.0763,\n",
       "          -9.6981, -10.6655,  -8.7827,  -8.0367,  -9.4789,  -3.6914, -10.6374,\n",
       "          -8.1679,  -8.9064,  -7.4665,  -9.9205]),\n",
       " 'full_model_pred_label': tensor(432)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4c6b5-4bb0-4cdf-bbe7-8a171e693c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a1fe853-1cf3-44b6-960c-9d3e94f89249",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_path = join(args.model_dir, args.model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "train_ds, test_ds = prepare_pararel_data(args)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=args.batch_size\n",
    ")\n",
    "\n",
    "eval_dl = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60a65079-fd0b-4f2b-8cc1-4420421fed43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb9b8d-5953-4a68-b6a0-885b0aaa563e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec2fc373-67f6-4d2e-8bac-f015147dfecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "# # download gpt2-small weights from EasyTransformer and save it\n",
    "# reference_gpt2 = EasyTransformer.from_pretrained(\"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False)\n",
    "# torch.save(reference_gpt2.state_dict(), join(args['model_dir'], 'gpt2-small/gpt2_small_weights.pt'))\n",
    "\n",
    "gpt_weights = torch.load(join(model_path, 'model_weights.pt')) \n",
    "circuit_gpt_config = CircuitGPTConfig(\n",
    "    debug=False,\n",
    "    gs_temp_weight=args.gs_temp_weight,\n",
    "    gs_temp_edge=args.gs_temp_edge,\n",
    "    use_weight_masks=False\n",
    ")\n",
    "circuit_gpt = CircuitGPT(circuit_gpt_config)\n",
    "circuit_gpt.load_pretrained_weight(gpt_weights)\n",
    "\n",
    "# load pretrained mask logits if necessary\n",
    "if args.resume_epoch_w > 0:\n",
    "    weight_mask_logits = torch.load(join(model_path), f'weight_mask_logits_{resume_epoch_w}.pt')\n",
    "    circuit_gpt.load_pretrained_weight_mask(weight_mask_logits)\n",
    "if args.resume_epoch_e > 0:\n",
    "    edge_mask_logits = torch.load(join(model_path), f'edge_mask_logits_{resume_epoch_e}.pt')\n",
    "    circuit_gpt.load_pretrained_edge_mask(edge_mask_logits)\n",
    "\n",
    "circuit_gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "545976c6-4dc1-4572-b4ae-7e00d387dd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d667ef465e374ccd9494a837fe5e2e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. mean pruned model accuracy: 0.0135,weight density: 1.0000,edge density: 1.0000\n"
     ]
    }
   ],
   "source": [
    "eval_acc, weight_density, edge_density = eval_model(\n",
    "    circuit_gpt, eval_dl, tokenizer, device, \n",
    "    use_weight_mask=False, use_edge_mask=False\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Epoch 0. mean pruned model accuracy: {eval_acc:.4f},\" + \n",
    "    f\"weight density: {weight_density:.4f},\" + \n",
    "    f\"edge density: {edge_density:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4c8f248-f8ab-4833-84e1-fdbf88b29696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9577f647fd5341fab405f725f2ff1a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/629 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. mean pruned model accuracy: 0.0174,weight density: 1.0000,edge density: 1.0000\n"
     ]
    }
   ],
   "source": [
    "eval_acc, weight_density, edge_density = eval_model(\n",
    "    circuit_gpt, train_dl, tokenizer, device, \n",
    "    use_weight_mask=False, use_edge_mask=False\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Epoch 0. mean pruned model accuracy: {eval_acc:.4f},\" + \n",
    "    f\"weight density: {weight_density:.4f},\" + \n",
    "    f\"edge density: {edge_density:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7885328-d943-4a85-8cae-a375d55202e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208.8438"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0135 * len(ds_test) + 0.0174 * len(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1d9cee-c5fe-4798-9b30-4e422c087549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7e6c61-25b6-4c9d-bb2e-b9ed2c761168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a299c7-5b16-4e18-95d1-3a901dcdf7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = circuit_gpt\n",
    "# model.eval()\n",
    "\n",
    "# # get weight and edge density     \n",
    "# model.turn_on_weight_masks(deterministic=True, reverse=False)  \n",
    "# _, _, weight_density = model.get_weight_density()       \n",
    "# model.turn_on_edge_masks(deterministic=True, reverse=False)  \n",
    "# _, _, edge_density = model.get_edge_density()\n",
    "\n",
    "\n",
    "# model.turn_off_weight_masks()    \n",
    "# model.turn_off_edge_masks()\n",
    "\n",
    "# total = len(eval_dl.dataset)\n",
    "# correct = 0\n",
    "\n",
    "# _, batch = next(enumerate(eval_dl))\n",
    "\n",
    "# batch_inputs = prepare_batch_inputs(batch, tokenizer)\n",
    "# batch_logits = model(batch_inputs['input_ids'].to(device))[0]  # (B, seq_len, vocab_size)\n",
    "# _, batch_preds = compute_faith_loss(batch_logits, batch_inputs)\n",
    "# # print(batch_logits_gb)\n",
    "# correct += (batch_preds == batch_inputs['labels']).sum().cpu().item()\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# model.turn_off_weight_masks()\n",
    "# model.turn_off_edge_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb94309-ac52-4b05-9e93-9764b1b4a83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f7315e1-0bae-4c08-b0af-f1355d025922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight_logits = [mask for _, mask in circuit_gpt.mask_logits_dict_weight.items()]\n",
    "edge_logits = [mask for _, mask in circuit_gpt.mask_logits_dict_edge.items()]\n",
    "\n",
    "# optim_weight = torch.optim.AdamW(weight_logits, lr=args.lr_weight)\n",
    "optim_edge = torch.optim.AdamW(edge_logits, lr=args.lr_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8bd1a-52b7-4d63-9dad-205fb192af10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac5b5784-ae53-4856-b41d-57e48ab96726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5726248717b49ac8c30d074e5c829da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e475bf514f424739aa95e6d3e39024bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45ce4b55d3e449694419bb730066837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. discovered circuit accuracy: 0.1046, complementary circuit accuracy: 0.0000, weight density: 1.0000, edge density: 0.5049\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m     optim_edge\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     41\u001b[0m     optim_edge\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m eval_acc_pruned, weight_density, edge_density \u001b[38;5;241m=\u001b[39m eval_model(\n\u001b[1;32m     45\u001b[0m     circuit_gpt, eval_dl, tokenizer, device, use_weight_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m eval_acc_complement, _, _ \u001b[38;5;241m=\u001b[39m eval_model(\n\u001b[1;32m     48\u001b[0m     circuit_gpt, eval_dl, tokenizer, device, use_weight_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     49\u001b[0m )\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/torch/cuda/memory.py:133\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 133\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_lambda_sparse(epoch, lambda_0, max_times=100., min_times=0.001, \n",
    "                      n_epoch_warmup=10, n_epoch_cooldown=10):\n",
    "\n",
    "    if epoch < n_epoch_warmup:\n",
    "        return lambda_0  + lambda_0 * (max_times - 1) * epoch / n_epoch_warmup\n",
    "        \n",
    "    elif epoch < n_epoch_warmup + n_epoch_cooldown:\n",
    "        return lambda_0 * max_times - lambda_0 * (max_times - min_times) * (epoch - n_epoch_warmup) / n_epoch_cooldown\n",
    "        \n",
    "    else:\n",
    "        return lambda_0 * min_times\n",
    "        \n",
    "# it takes about 35 mins to run 100 epochs of edge mask training on one A100 GPU with batch_size=32\n",
    "for epoch in tqdm(range(args.train_epochs_edge)):\n",
    "    lambda_sparse_edge = get_lambda_sparse(\n",
    "        epoch, \n",
    "        lambda_0=args.lambda_sparse_edge_init,\n",
    "        max_times=args.max_times_lambda_sparse, \n",
    "        min_times=args.min_times_lambda_sparse, \n",
    "        n_epoch_warmup=args.n_epoch_warmup_lambda_sparse,\n",
    "        n_epoch_cooldown=args.n_epoch_cooldown_lambda_sparse,\n",
    "    )\n",
    "    lambda_complete_edge = args.lambda_complete_edge_init\n",
    "    \n",
    "    for batch in tqdm(train_dl):\n",
    "        batch_inputs = prepare_batch_inputs(batch, tokenizer)\n",
    "        \n",
    "        circuit_gpt.turn_on_edge_masks(deterministic=False)\n",
    "        sparse_loss_edge = circuit_gpt.edge_sparseness_loss()\n",
    "    \n",
    "        batch_logits = circuit_gpt(batch_inputs['input_ids'].to(device))[0] \n",
    "        faith_loss_edge, _ = compute_faith_loss(batch_logits, batch_inputs) \n",
    "        \n",
    "        circuit_gpt.turn_on_edge_masks(deterministic=False, reverse=True)\n",
    "        batch_logits = circuit_gpt(batch_inputs['input_ids'].to(device))[0] \n",
    "        complete_loss_edge, _ = compute_complete_loss(batch_logits, batch_inputs) \n",
    "        \n",
    "        loss_edge = faith_loss_edge + sparse_loss_edge *  lambda_sparse_edge + complete_loss_edge * lambda_complete_edge\n",
    "        loss_edge.backward()\n",
    "        optim_edge.step()\n",
    "        optim_edge.zero_grad()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    eval_acc_pruned, weight_density, edge_density = eval_model(\n",
    "        circuit_gpt, eval_dl, tokenizer, device, use_weight_mask=False, reverse=False\n",
    "    )\n",
    "    eval_acc_complement, _, _ = eval_model(\n",
    "        circuit_gpt, eval_dl, tokenizer, device, use_weight_mask=False, reverse=True\n",
    "    )\n",
    "    print(\n",
    "        \"Epoch {}. discovered circuit accuracy: {:.4f}, complementary circuit accuracy: {:.4f}, weight density: {:.4f}, edge density: {:.4f}\".format(\n",
    "            epoch + 1, eval_acc_pruned, eval_acc_complement, weight_density, edge_density)\n",
    "    )\n",
    "\n",
    "    # save good edge masks\n",
    "    if eval_acc_pruned > 0.95 and edge_density < 0.05:\n",
    "        torch.save(\n",
    "            circuit_gpt.mask_logits_dict_edge,\n",
    "            join(args.results_dir, f'mask_logits_dict_edge_oqa_edge_only_{epoch}.pt')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e1a80-11f8-476d-a83b-a96d910cd881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad7f34-1396-4450-bcf2-e174be265164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52cc597a-b158-4b38-9a4f-2aae6c47cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# circuit_gpt initialization\n",
    "device = torch.device('cuda')    \n",
    "gpt_weights = torch.load(join(model_path, 'model_weights.pt')) \n",
    "circuit_gpt_config = CircuitGPTConfig(\n",
    "    debug=False,\n",
    "    gs_temp_weight=args.gs_temp_weight,\n",
    "    gs_temp_edge=args.gs_temp_edge,\n",
    "    use_weight_masks=True,\n",
    "    logits_w_init=args.logits_w_init\n",
    "    \n",
    ")\n",
    "circuit_gpt = CircuitGPT(circuit_gpt_config)\n",
    "circuit_gpt.load_pretrained_weight(gpt_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c19f11b8-3dbc-4884-a7a6-d5f701b60aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CircuitGPT(\n",
       "  (embed): Embed()\n",
       "  (pos_embed): PosEmbed()\n",
       "  (ln_final): LayerNorm()\n",
       "  (unembed): Unembed()\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x TransformerBlock(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Attention()\n",
       "      (ln2): LayerNorm()\n",
       "      (mlp): MLP()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99daafb1-77a1-4dd1-a80a-894d1e65d3f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['blocks.0.attn.W_Q', 'blocks.0.attn.b_Q', 'blocks.0.attn.W_K', 'blocks.0.attn.b_K', 'blocks.0.attn.W_V', 'blocks.0.attn.b_V', 'blocks.0.attn.W_O', 'blocks.0.attn.b_O', 'blocks.0.mlp.W_in', 'blocks.0.mlp.b_in', 'blocks.0.mlp.W_out', 'blocks.0.mlp.b_out', 'blocks.1.attn.W_Q', 'blocks.1.attn.b_Q', 'blocks.1.attn.W_K', 'blocks.1.attn.b_K', 'blocks.1.attn.W_V', 'blocks.1.attn.b_V', 'blocks.1.attn.W_O', 'blocks.1.attn.b_O', 'blocks.1.mlp.W_in', 'blocks.1.mlp.b_in', 'blocks.1.mlp.W_out', 'blocks.1.mlp.b_out', 'blocks.2.attn.W_Q', 'blocks.2.attn.b_Q', 'blocks.2.attn.W_K', 'blocks.2.attn.b_K', 'blocks.2.attn.W_V', 'blocks.2.attn.b_V', 'blocks.2.attn.W_O', 'blocks.2.attn.b_O', 'blocks.2.mlp.W_in', 'blocks.2.mlp.b_in', 'blocks.2.mlp.W_out', 'blocks.2.mlp.b_out', 'blocks.3.attn.W_Q', 'blocks.3.attn.b_Q', 'blocks.3.attn.W_K', 'blocks.3.attn.b_K', 'blocks.3.attn.W_V', 'blocks.3.attn.b_V', 'blocks.3.attn.W_O', 'blocks.3.attn.b_O', 'blocks.3.mlp.W_in', 'blocks.3.mlp.b_in', 'blocks.3.mlp.W_out', 'blocks.3.mlp.b_out', 'blocks.4.attn.W_Q', 'blocks.4.attn.b_Q', 'blocks.4.attn.W_K', 'blocks.4.attn.b_K', 'blocks.4.attn.W_V', 'blocks.4.attn.b_V', 'blocks.4.attn.W_O', 'blocks.4.attn.b_O', 'blocks.4.mlp.W_in', 'blocks.4.mlp.b_in', 'blocks.4.mlp.W_out', 'blocks.4.mlp.b_out', 'blocks.5.attn.W_Q', 'blocks.5.attn.b_Q', 'blocks.5.attn.W_K', 'blocks.5.attn.b_K', 'blocks.5.attn.W_V', 'blocks.5.attn.b_V', 'blocks.5.attn.W_O', 'blocks.5.attn.b_O', 'blocks.5.mlp.W_in', 'blocks.5.mlp.b_in', 'blocks.5.mlp.W_out', 'blocks.5.mlp.b_out', 'blocks.6.attn.W_Q', 'blocks.6.attn.b_Q', 'blocks.6.attn.W_K', 'blocks.6.attn.b_K', 'blocks.6.attn.W_V', 'blocks.6.attn.b_V', 'blocks.6.attn.W_O', 'blocks.6.attn.b_O', 'blocks.6.mlp.W_in', 'blocks.6.mlp.b_in', 'blocks.6.mlp.W_out', 'blocks.6.mlp.b_out', 'blocks.7.attn.W_Q', 'blocks.7.attn.b_Q', 'blocks.7.attn.W_K', 'blocks.7.attn.b_K', 'blocks.7.attn.W_V', 'blocks.7.attn.b_V', 'blocks.7.attn.W_O', 'blocks.7.attn.b_O', 'blocks.7.mlp.W_in', 'blocks.7.mlp.b_in', 'blocks.7.mlp.W_out', 'blocks.7.mlp.b_out', 'blocks.8.attn.W_Q', 'blocks.8.attn.b_Q', 'blocks.8.attn.W_K', 'blocks.8.attn.b_K', 'blocks.8.attn.W_V', 'blocks.8.attn.b_V', 'blocks.8.attn.W_O', 'blocks.8.attn.b_O', 'blocks.8.mlp.W_in', 'blocks.8.mlp.b_in', 'blocks.8.mlp.W_out', 'blocks.8.mlp.b_out', 'blocks.9.attn.W_Q', 'blocks.9.attn.b_Q', 'blocks.9.attn.W_K', 'blocks.9.attn.b_K', 'blocks.9.attn.W_V', 'blocks.9.attn.b_V', 'blocks.9.attn.W_O', 'blocks.9.attn.b_O', 'blocks.9.mlp.W_in', 'blocks.9.mlp.b_in', 'blocks.9.mlp.W_out', 'blocks.9.mlp.b_out', 'blocks.10.attn.W_Q', 'blocks.10.attn.b_Q', 'blocks.10.attn.W_K', 'blocks.10.attn.b_K', 'blocks.10.attn.W_V', 'blocks.10.attn.b_V', 'blocks.10.attn.W_O', 'blocks.10.attn.b_O', 'blocks.10.mlp.W_in', 'blocks.10.mlp.b_in', 'blocks.10.mlp.W_out', 'blocks.10.mlp.b_out', 'blocks.11.attn.W_Q', 'blocks.11.attn.b_Q', 'blocks.11.attn.W_K', 'blocks.11.attn.b_K', 'blocks.11.attn.W_V', 'blocks.11.attn.b_V', 'blocks.11.attn.W_O', 'blocks.11.attn.b_O', 'blocks.11.mlp.W_in', 'blocks.11.mlp.b_in', 'blocks.11.mlp.W_out', 'blocks.11.mlp.b_out'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit_gpt.mask_logits_dict_weight.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c191b81-562e-4d68-ad3c-b38c80a6f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_attn_weight = 0\n",
    "n_weight = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for key, mask in circuit_gpt.mask_logits_dict_weight.items():\n",
    "        n_weight += torch.ones_like(mask).sum()\n",
    "        if 'attn' in key:\n",
    "            n_attn_weight += torch.ones_like(mask).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50d50499-9c9b-49a2-b644-783c20bcd001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28348416., device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_attn_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daf3d3bf-09f6-42bb-a04a-9cc8b53252b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3334, device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_attn_weight / n_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cc85f-0bf1-4080-a95b-877df81d0d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157c9b4f-ad16-4fae-92be-6108cd2eb0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
