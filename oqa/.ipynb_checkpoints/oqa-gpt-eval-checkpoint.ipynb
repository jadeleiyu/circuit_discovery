{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e85ab25c-7bc9-48ca-a2fb-7595f5502267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import pickle\n",
    "import transformer_lens\n",
    "from torch.optim import AdamW\n",
    "from os.path import join\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_from_disk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from circuit_gpt import CircuitGPT, CircuitGPTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d06a9be2-5fc1-4110-928e-e55f5ca050ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_pararel_data(args):\n",
    "    \n",
    "    with open(join(args.data_dir, args.data_name)) as open_file:\n",
    "        pararel_rel_data = json.load(open_file)\n",
    "    rel_ids = args.pararel_rel_ids.split(' ')\n",
    "    data = []\n",
    "    for rel_id in rel_ids:\n",
    "        data += pararel_rel_data[rel_id]\n",
    "\n",
    "    ds_dict = {\n",
    "        'prompt': [],\n",
    "        'answer': [],\n",
    "    }\n",
    "    for entry in data:\n",
    "        prompt = entry[0][0].replace(' [MASK] .', '')\n",
    "        prompt = prompt.replace(' [MASK].', '')\n",
    "        assert '[MASK]' not in prompt\n",
    "        target = entry[0][1]\n",
    "        ds_dict['prompt'].append(prompt)\n",
    "        ds_dict['answer'].append(' ' + target)\n",
    "\n",
    "    train_idx, test_idx = train_test_split(np.arange(len(data)), test_size=args.test_ratio)\n",
    "    train_ds_dict = {\n",
    "        'prompt': [ds_dict['prompt'][i] for i in train_idx], \n",
    "        'answer': [ds_dict['answer'][i] for i in train_idx]\n",
    "    }\n",
    "    test_ds_dict = {\n",
    "        'prompt': [ds_dict['prompt'][i] for i in test_idx], \n",
    "        'answer': [ds_dict['answer'][i] for i in test_idx]\n",
    "    }\n",
    "    \n",
    "    train_ds = Dataset.from_dict(train_ds_dict)\n",
    "    test_ds = Dataset.from_dict(test_ds_dict)\n",
    "    \n",
    "    return train_ds, test_ds\n",
    "    \n",
    "\n",
    "def prepare_batch_inputs(batch, tokenizer):\n",
    "    batch_inputs = tokenizer(\n",
    "        batch['prompt'], return_tensors='pt', padding=True\n",
    "    )\n",
    "    batch_seq_lens = batch_inputs.attention_mask.sum(-1)\n",
    "\n",
    "    return {\n",
    "        'input_ids': batch_inputs.input_ids,\n",
    "        'seq_lens': batch_seq_lens,\n",
    "        'label': batch['label']\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1f75ef8-2d65-4532-b591-d25c29a426fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DiffMaskArgs:\n",
    "    model_dir: str = '/home/leiyu/projects/def-yangxu/leiyu/LMs/'\n",
    "    data_dir: str = '/home/leiyu/projects/def-yangxu/leiyu/circuit-discovery/data/'\n",
    "    results_dir: str = '/home/leiyu/scratch/circuit-discovery/mask_logits/'\n",
    "    data_name: str = 'pararel_data_all.json'\n",
    "    pararel_rel_ids: str = 'P36 P1376'\n",
    "    model_name: str = 'gpt2-small'\n",
    "    gs_temp_weight: float = 0.01\n",
    "    gs_temp_edge: float = 1.0\n",
    "    logits_w_init: float = 0.0\n",
    "    logits_e_init: float = 0.0\n",
    "    test_ratio: float = 0.0\n",
    "    batch_size: int = 16\n",
    "    train_epochs_weight: int = 1000\n",
    "    train_epochs_edge: int = 50\n",
    "    lr_weight: float = 0.1\n",
    "    lr_edge: float = 0.1\n",
    "    lambda_sparse_weight_init: float = 1.\n",
    "    lambda_sparse_edge_init: float = 1.\n",
    "    lambda_complete_weight_init: float = 1.\n",
    "    lambda_complete_edge_init: float = 1.\n",
    "    save_every: int = 5\n",
    "    resume_epoch_w: int = 0\n",
    "    resume_epoch_e: int = 0\n",
    "    use_weight_masks: bool = False\n",
    "    n_epoch_warmup_lambda_sparse: int = 20\n",
    "    n_epoch_cooldown_lambda_sparse: int = 20\n",
    "    max_times_lambda_sparse: float = 100.\n",
    "    min_times_lambda_sparse: float = 0.01\n",
    "    random_seed: int = 0\n",
    "    \n",
    "\n",
    "def compute_faith_loss(batch_logits, batch_inputs):\n",
    "    # batch_logits: (B, seq_len, vocab_size)\n",
    "    batch_seq_lens = batch_inputs['seq_lens']\n",
    "    batch_size = batch_logits.shape[0]\n",
    "\n",
    "    batch_logits_next_tok = batch_logits[torch.arange(batch_size), batch_seq_lens - 1]  # (B, vocab_size)\n",
    "    batch_labels = batch_inputs['labels'].long().to(batch_logits_next_tok.device)\n",
    "    batch_faith_loss = nn.functional.cross_entropy(batch_logits_next_tok, batch_labels)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_preds = torch.argsort(batch_logits_next_tok, -1)[:, -1].cpu()\n",
    "\n",
    "    return batch_faith_loss, batch_preds\n",
    "\n",
    "\n",
    "def compute_complete_loss(batch_logits, batch_inputs):\n",
    "    # batch_logits: (B, seq_len, vocab_size)\n",
    "    batch_seq_lens = batch_inputs['seq_lens']\n",
    "    batch_size = batch_logits.shape[0]\n",
    "\n",
    "    batch_logits_next_tok = batch_logits[torch.arange(batch_size), batch_seq_lens - 1]  # (B, vocab_size)\n",
    "\n",
    "    batch_probs_uniform = torch.ones(batch_logits_next_tok.shape).to(batch_logits_next_tok.device) / batch_logits_next_tok.shape[-1]\n",
    "    batch_complete_loss = nn.functional.cross_entropy(batch_logits_next_tok, batch_probs_uniform)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_preds = torch.argsort(batch_logits_next_tok, -1)[:, -1].cpu()\n",
    "\n",
    "    return batch_complete_loss, batch_preds\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model, eval_dl, tokenizer, device, use_weight_mask=True, use_edge_mask=True, reverse=False):\n",
    "    model.eval()\n",
    "\n",
    "    # get weight and edge density     \n",
    "    model.turn_on_weight_masks(deterministic=True, reverse=reverse)  \n",
    "    _, _, weight_density = model.get_weight_density()       \n",
    "    model.turn_on_edge_masks(deterministic=True, reverse=reverse)  \n",
    "    _, _, edge_density = model.get_edge_density()\n",
    "\n",
    "    if not use_weight_mask:\n",
    "        model.turn_off_weight_masks()\n",
    "    if not use_edge_mask:     \n",
    "        model.turn_off_edge_masks()\n",
    "\n",
    "    total = len(eval_dl.dataset)\n",
    "    correct = 0\n",
    "\n",
    "    n_batch = int(len(eval_dl.dataset) / eval_dl.batch_size) + 1\n",
    "    for batch in tqdm(eval_dl, total=n_batch):\n",
    "        batch_inputs = prepare_batch_inputs(batch, tokenizer)\n",
    "        batch_logits = model(batch_inputs['input_ids'].to(device))[0]  # (B, seq_len, vocab_size)\n",
    "        _, batch_preds = compute_faith_loss(batch_logits, batch_inputs)\n",
    "        # print(batch_logits_gb)\n",
    "        correct += (batch_preds == batch_inputs['labels']).sum().cpu().item()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    model.turn_off_weight_masks()\n",
    "    model.turn_off_edge_masks()\n",
    "\n",
    "    acc = correct / total\n",
    "\n",
    "    return acc, weight_density, edge_density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f607bae3-d491-46d2-bf15-5f363408a356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = DiffMaskArgs()\n",
    "model_path = join(args.model_dir, args.model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ac62a99b-8e17-4ab7-8bf4-b0b940112be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(args.data_dir, args.data_name)) as open_file:\n",
    "        pararel_rel_data = json.load(open_file)  \n",
    "    \n",
    "rel_ids = args.pararel_rel_ids.split(' ')\n",
    "data = []\n",
    "for rel_id in rel_ids:\n",
    "    data += pararel_rel_data[rel_id]\n",
    "\n",
    "capital_vocab = []\n",
    "ds_dict = {\n",
    "    'prompt': [],\n",
    "    'answer': [],\n",
    "}\n",
    "\n",
    "for entry in data:\n",
    "    prompt = entry[0][0].replace(' [MASK] .', '')\n",
    "    prompt = prompt.replace(' [MASK].', '')\n",
    "    assert '[MASK]' not in prompt\n",
    "    target = entry[0][1]\n",
    "    ds_dict['prompt'].append(prompt)\n",
    "    ds_dict['answer'].append(' ' + target)\n",
    "    capital_vocab.append(' ' + target)\n",
    "\n",
    "capital_vocab = list(set([data['answer'] for data in ds_dict]))\n",
    "capital_vocab_idx = torch.tensor([\n",
    "    input_ids[0] for input_ids in tokenizer(capital_vocab).input_ids\n",
    "])\n",
    "\n",
    "capital_vocab2class_id = {\n",
    "    capital_vocab_idx[i].item():i for i in range(len(capital_vocab_idx)) \n",
    "}\n",
    "\n",
    "capital_name2vocab_id = {capital: capital_vocab_id.item() for capital, capital_vocab_id in zip(capital_vocab, capital_vocab_idx)}\n",
    "\n",
    "ds_dict['label'] = [\n",
    "    capital_vocab2class_id[capital_name2vocab_id[answer]] for answer in ds_dict['answer']\n",
    "]\n",
    "\n",
    "\n",
    "ds = Dataset.from_dict(ds_dict)\n",
    "dl = DataLoader(ds, batch_size=args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7b0979a-6347-41b0-8602-e946373f7f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'The capital of Alexandria Governorate is',\n",
       " 'answer': ' Alexandria',\n",
       " 'label': 27872}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaec9347-7582-4c7a-ab81-5d5e2f22dabd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0dd9812-3e13-412f-ace8-8ff6306abf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "# # download gpt2-small weights from EasyTransformer and save it\n",
    "# reference_gpt2 = EasyTransformer.from_pretrained(\"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False)\n",
    "# torch.save(reference_gpt2.state_dict(), join(args['model_dir'], 'gpt2-small/gpt2_small_weights.pt'))\n",
    "\n",
    "gpt_weights = torch.load(join(model_path, 'model_weights.pt')) \n",
    "circuit_gpt_config = CircuitGPTConfig(\n",
    "    debug=False,\n",
    "    gs_temp_weight=args.gs_temp_weight,\n",
    "    gs_temp_edge=args.gs_temp_edge,\n",
    "    use_weight_masks=False\n",
    ")\n",
    "circuit_gpt = CircuitGPT(circuit_gpt_config)\n",
    "circuit_gpt.load_pretrained_weight(gpt_weights)\n",
    "\n",
    "# load pretrained mask logits if necessary\n",
    "if args.resume_epoch_w > 0:\n",
    "    weight_mask_logits = torch.load(join(model_path), f'weight_mask_logits_{resume_epoch_w}.pt')\n",
    "    circuit_gpt.load_pretrained_weight_mask(weight_mask_logits)\n",
    "if args.resume_epoch_e > 0:\n",
    "    edge_mask_logits = torch.load(join(model_path), f'edge_mask_logits_{resume_epoch_e}.pt')\n",
    "    circuit_gpt.load_pretrained_edge_mask(edge_mask_logits)\n",
    "\n",
    "circuit_gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deea8028-3172-4e8d-841b-13dddb6142b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4835452f-a132-4f13-aecc-ebecb4f39a37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa99f76f72a4816b61ba1bf34241fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = circuit_gpt\n",
    "model.eval()\n",
    "\n",
    "model.turn_off_weight_masks()\n",
    "model.turn_off_edge_masks()\n",
    "\n",
    "total = len(dl.dataset)\n",
    "correct = 0\n",
    "\n",
    "model_predictions = []\n",
    "n_batch = int(len(dl.dataset) / dl.batch_size) + 1\n",
    "\n",
    "for batch in tqdm(dl, total=n_batch):\n",
    "    batch_inputs = prepare_batch_inputs(batch, tokenizer)\n",
    "    with torch.no_grad():\n",
    "        batch_logits = model(batch_inputs['input_ids'].to(device))[0]  # (B, seq_len, vocab_size)\n",
    "        batch_seq_lens = batch_inputs['seq_lens']\n",
    "        batch_size = batch_logits.shape[0]\n",
    "        batch_logits_next_tok = batch_logits[torch.arange(batch_size), batch_seq_lens - 1][:, capital_vocab_idx]  # (B, capital_vocab_size)\n",
    "        batch_pred_cap_ids = torch.argsort(batch_logits_next_tok, -1)[:, -1].cpu()\n",
    "        for pred_cap_id, label in zip(batch_pred_cap_ids, batch['label']):\n",
    "            if capital_vocab_idx[pred_cap_id] == label:\n",
    "                correct += 1\n",
    "        # correct += (batch_pred_cap_ids == torch.tensor(batch_inputs['label'])).sum()\n",
    "     \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "acc = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9e5c87d0-d067-43f2-9fa2-e667f565d5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3479188900747065"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "337ee45c-1502-4de4-bb3c-467c075b9415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d9711c66-0d14-4c13-9bfa-02021f71ab7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "937"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61091c2-330f-4da7-855f-4b373714aaa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1700cfe8-24df-4663-ba7c-c0e17d9bf36f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
