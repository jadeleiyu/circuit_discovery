{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601155a3-79f0-4ab9-a565-2b89ce4ef7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import yaml\n",
    "import torch\n",
    "from os.path import join\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/leiyu/projects/def-yangxu/leiyu/circuit-discovery')\n",
    "\n",
    "mask_dir = '/home/leiyu/scratch/circuit-discovery/mask_logits/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "964c59f1-df34-4053-b979-3c35f65bcb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from graphviz import Digraph\n",
    "\n",
    "\n",
    "def no_revisit(func):\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        if not self.visited:\n",
    "            func(self, *args, **kwargs)\n",
    "            self.visited = True\n",
    "    return wrapper\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.children = []\n",
    "        self.parents = []\n",
    "\n",
    "        self.visited = False\n",
    "\n",
    "    def __call__(self):\n",
    "        if self.name == 'input':\n",
    "            return ('input',)\n",
    "        elif self.name == 'output':\n",
    "            return ('output',)\n",
    "        elif self.name.startswith('attn'):\n",
    "            t, i, j = self.name.split('_')\n",
    "            i, j = int(i), int(j)\n",
    "            return t, i, j\n",
    "        elif self.name.startswith('mlp'):\n",
    "            t, i = self.name.split('_')\n",
    "            i = int(i)\n",
    "            return t, i\n",
    "\n",
    "\n",
    "    @property\n",
    "    def color(self):\n",
    "        if self.name == 'input':\n",
    "            return 'blue'\n",
    "        elif self.name == 'output':\n",
    "            return 'blue'\n",
    "        elif self.name.startswith('attn'):\n",
    "            return 'red'\n",
    "        elif self.name.startswith('mlp'):\n",
    "            return 'green'\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "        child.parents.append(self)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'[{self.name}]'\n",
    "\n",
    "\n",
    "\n",
    "    # @no_revisit\n",
    "    def dfs_connections(self):\n",
    "        conns = set()\n",
    "        for child in self.children:\n",
    "            # conns.add((self.name, child.name))\n",
    "            conns.add((child.name, self.name))\n",
    "            conns = conns.union(child.dfs_connections())\n",
    "        return conns\n",
    "\n",
    "    # @no_revisit\n",
    "    def dfs_connections_r(self):\n",
    "        conns = set()\n",
    "        for parent in self.parents:\n",
    "            # conns.add((parent.name, self.name))\n",
    "            conns.add((self.name, parent.name))\n",
    "            conns = conns.union(parent.dfs_connections_r())\n",
    "        return conns\n",
    "\n",
    "\n",
    "\n",
    "class GPTGraph:\n",
    "    def __init__(self):\n",
    "        nodes = {\n",
    "            'input': Node('input'),\n",
    "            'output': Node('output'),\n",
    "        }\n",
    "        for i in range(12):\n",
    "            for j in range(12):\n",
    "                nodes[f'attn_{i}_{j}_Q'] = Node(f'attn_{i}_{j}_Q')\n",
    "                nodes[f'attn_{i}_{j}_K'] = Node(f'attn_{i}_{j}_K')\n",
    "                nodes[f'attn_{i}_{j}_V'] = Node(f'attn_{i}_{j}_V')\n",
    "                nodes[f'attn_{i}_{j}_O'] = Node(f'attn_{i}_{j}_O')\n",
    "            nodes[f'mlp_{i}'] = Node(f'mlp_{i}')\n",
    "        self.nodes = nodes\n",
    "        self.input_node = self.nodes['input']\n",
    "        self.output_node = self.nodes['output']\n",
    "        self.attn = lambda i,j,M: self.nodes[f'attn_{i}_{j}_{M}']\n",
    "        self.mlp = lambda i: self.nodes[f'mlp_{i}']\n",
    "\n",
    "    def reset_graph(self):\n",
    "        for node in self.nodes.values():\n",
    "            node.visited = False\n",
    "\n",
    "    def set_connections(self, masks):\n",
    "        output_mask, attn_Q_masks, attn_K_masks, attn_V_masks, edge_mask_mlp = masks\n",
    "\n",
    "        for i in range(12):\n",
    "            output_mask_i = output_mask[1:][i*13:(1+i)*13]\n",
    "            mlp_i_output_edge = output_mask_i[-1]\n",
    "            if mlp_i_output_edge == 1:\n",
    "                self.output_node.add_child(self.mlp(i))\n",
    "\n",
    "            for j in range(12):\n",
    "                attn_ij_output_edge = output_mask_i[j]\n",
    "                if attn_ij_output_edge == 1:\n",
    "                    self.output_node.add_child(self.attn(i,j,'O'))\n",
    "\n",
    "        for i in range(12):\n",
    "            edge_mask_mlps_i = edge_mask_mlp[i]\n",
    "            if edge_mask_mlps_i[0] == 1:\n",
    "                self.mlp(i).add_child(self.input_node)\n",
    "            for j in range(i+1):\n",
    "                edge_mask_mlps_ij = edge_mask_mlps_i[1:][j*13:(1+j)*13]\n",
    "                if j < i:\n",
    "                    edge_mask_mlps_i_mlp_j = edge_mask_mlps_ij[-1]\n",
    "                    if edge_mask_mlps_i_mlp_j == 1:\n",
    "                        self.mlp(i).add_child(self.mlp(j))\n",
    "                for k in range(12):\n",
    "                    edge_mask_mlps_i_attn_jk = edge_mask_mlps_ij[k]\n",
    "                    if edge_mask_mlps_i_attn_jk == 1:\n",
    "                        self.mlp(i).add_child(self.attn(j,k,'O'))\n",
    "\n",
    "        for i in range(12):\n",
    "            for j in range(12):\n",
    "                self.attn(i,j,'O').add_child(self.attn(i,j,'Q'))\n",
    "                self.attn(i,j,'O').add_child(self.attn(i,j,'K'))\n",
    "                self.attn(i,j,'O').add_child(self.attn(i,j,'V'))\n",
    "                \n",
    "                edge_mask_attn_ij_Q = attn_Q_masks[i][:, j]\n",
    "                edge_mask_attn_ij_K = attn_K_masks[i][:, j]\n",
    "                edge_mask_attn_ij_V = attn_V_masks[i][:, j]\n",
    "                \n",
    "                if edge_mask_attn_ij_Q[0] == 1:\n",
    "                    self.attn(i,j,'Q').add_child(self.input_node)\n",
    "                if edge_mask_attn_ij_K[0] == 1:\n",
    "                    self.attn(i,j,'K').add_child(self.input_node)\n",
    "                if edge_mask_attn_ij_V[0] == 1:\n",
    "                    self.attn(i,j,'V').add_child(self.input_node)\n",
    "                    \n",
    "                for k in range(i):\n",
    "                    edge_mask_attn_ij_k_Q = edge_mask_attn_ij_Q[1:][k*13:(1+k)*13]\n",
    "                    edge_mask_attn_ij_k_K = edge_mask_attn_ij_K[1:][k*13:(1+k)*13]\n",
    "                    edge_mask_attn_ij_k_V = edge_mask_attn_ij_V[1:][k*13:(1+k)*13]\n",
    "\n",
    "                    if edge_mask_attn_ij_k_Q[-1] == 1:\n",
    "                        self.attn(i,j,'Q').add_child(self.mlp(k))\n",
    "                    if edge_mask_attn_ij_k_K[-1] == 1:\n",
    "                        self.attn(i,j,'K').add_child(self.mlp(k))\n",
    "                    if edge_mask_attn_ij_k_V[-1] == 1:\n",
    "                        self.attn(i,j,'V').add_child(self.mlp(k))\n",
    "                        \n",
    "                    for l in range(12):\n",
    "                        if edge_mask_attn_ij_k_Q[l] == 1:\n",
    "                            self.attn(i,j,'Q').add_child(self.attn(k,l,'O'))\n",
    "                        if edge_mask_attn_ij_k_K[l] == 1:\n",
    "                            self.attn(i,j,'K').add_child(self.attn(k,l,'O'))\n",
    "                        if edge_mask_attn_ij_k_V[l] == 1:\n",
    "                            self.attn(i,j,'V').add_child(self.attn(k,l,'O'))\n",
    "            \n",
    "\n",
    "    \n",
    "    def render_plot(self, fig_name, mode='both'):\n",
    "        \n",
    "        edges, nodes = self.get_connections(mode)\n",
    "        graph = Digraph()\n",
    "        \n",
    "        for node in nodes:\n",
    "            graph.node(node.name, color=node.color)\n",
    "            \n",
    "        graph.edges(edges)\n",
    "        \n",
    "        graph.render(fig_name)\n",
    "\n",
    "\n",
    "    def get_connections(self, mode='both'):\n",
    "\n",
    "        if mode == 'dfs':\n",
    "            conns = self.output_node.dfs_connections()\n",
    "        elif mode == 'dfs_r':\n",
    "            conns = self.input_node.dfs_connections_r()\n",
    "        elif mode == 'both':\n",
    "            conns = self.output_node.dfs_connections()\n",
    "            conns_r = self.input_node.dfs_connections_r()\n",
    "            conns = conns.intersection(conns_r)\n",
    "        elif mode == 'all':\n",
    "            conns = set()\n",
    "            for node in self.nodes.values():\n",
    "                for child in node.children:\n",
    "                    conns.add((child.name, node.name))\n",
    "                    # conns.add((node.name, child.name))\n",
    "        nodes = []\n",
    "        for e in conns:\n",
    "            nodes.append(self.nodes[e[0]])\n",
    "            nodes.append(self.nodes[e[1]])\n",
    "        return conns, set(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43cf43b2-a9c3-46c9-af1d-42897271f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_ablation(mask_logits_dict_edge, layer_is, head_js):\n",
    "    ablated_mask_logits_dict_edge = {k:torch.clone(v) for k,v in mask_logits_dict_edge.items()}\n",
    "    for layer_i, head_j in zip(layer_is, head_js):\n",
    "        for k in range(layer_i, 12):\n",
    "            mlp_masks_logits_k = ablated_mask_logits_dict_edge[f'blocks.{k}.edge_mask_mlp_logits']\n",
    "            mlp_masks_logits_ki = mlp_masks_logits_k[1:][layer_i*13:(1+layer_i)*13]\n",
    "            mlp_masks_logits_ki[head_j] = -1\n",
    "    \n",
    "            if k > layer_i:\n",
    "                for l in range(12):\n",
    "                    attn_q_masks_logits_kli = ablated_mask_logits_dict_edge[f'blocks.{k}.edge_mask_attention_q_logits'][:,l][1:][layer_i*13:(layer_i+1)*13]\n",
    "                    attn_k_masks_logits_kli = ablated_mask_logits_dict_edge[f'blocks.{k}.edge_mask_attention_k_logits'][:,l][1:][layer_i*13:(layer_i+1)*13]\n",
    "                    attn_v_masks_logits_kli = ablated_mask_logits_dict_edge[f'blocks.{k}.edge_mask_attention_v_logits'][:,l][1:][layer_i*13:(layer_i+1)*13]\n",
    "                    \n",
    "                    # print(attn_q_masks_logits_kli.shape)\n",
    "                    \n",
    "                    attn_q_masks_logits_kli[head_j] = -1.\n",
    "                    attn_k_masks_logits_kli[head_j] = -1.\n",
    "                    attn_v_masks_logits_kli[head_j] = -1.\n",
    "    \n",
    "        ablated_mask_logits_dict_edge['edge_mask_output_logits'][1:][layer_i*13:(1+layer_i)*13][head_j] = -1.\n",
    "            \n",
    "    return ablated_mask_logits_dict_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a9c1afb-9fee-4724-993b-a430711715aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_idx, n_epoch_w, n_epoch_e = 0, 0, 66\n",
    "\n",
    "mask_logits_dict_edge = torch.load(\n",
    "    join(mask_dir, f'mask_logits_dict_edge_ioi_{ds_idx}_weight_{n_epoch_w}_edge_{n_epoch_e}.pt')\n",
    ")\n",
    "\n",
    "mask_logits_dict_edge = {k:v.detach().cpu() for k,v in mask_logits_dict_edge.items()}\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# l = 3\n",
    "# layer_is = torch.repeat_interleave(torch.arange(l),12)\n",
    "# head_js = torch.arange(12).repeat(l)\n",
    "\n",
    "# mask_logits_dict_edge = head_ablation(mask_logits_dict_edge, layer_is, head_js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b09f816c-17e6-457d-b8f8-820bb2a2bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_graphs = []\n",
    "ds_idx_list, ns_epoch_w, ns_epoch_e = [0,1,2], [0,0,0], [66, 63, ]\n",
    "\n",
    "for ds_idx, n_epoch_w, n_epoch_e in zip(ds_idx_list, ns_epoch_w, ns_epoch_e):\n",
    "    mask_logits_dict_edge = torch.load(\n",
    "        join(mask_dir, f'mask_logits_dict_edge_ioi_{ds_idx}_weight_{n_epoch_w}_edge_{n_epoch_e}.pt')\n",
    "    )\n",
    "    output_mask = torch.where(mask_logits_dict_edge['edge_mask_output_logits'] > 0., 1., 0.)\n",
    "    attn_q_masks, attn_k_masks, attn_v_masks = [], [], []\n",
    "    mlp_masks = []\n",
    "    \n",
    "    for i in range(12):\n",
    "        attn_q_masks_logits_i = mask_logits_dict_edge[f'blocks.{i}.edge_mask_attention_q_logits']\n",
    "        attn_k_masks_logits_i = mask_logits_dict_edge[f'blocks.{i}.edge_mask_attention_k_logits']\n",
    "        attn_v_masks_logits_i = mask_logits_dict_edge[f'blocks.{i}.edge_mask_attention_v_logits']\n",
    "        mlp_masks_logits_i = mask_logits_dict_edge[f'blocks.{i}.edge_mask_mlp_logits']\n",
    "    \n",
    "        attn_q_masks.append(torch.where(attn_q_masks_logits_i > 0., 1., 0.))\n",
    "        attn_k_masks.append(torch.where(attn_k_masks_logits_i > 0., 1., 0.))\n",
    "        attn_v_masks.append(torch.where(attn_v_masks_logits_i > 0., 1., 0.))\n",
    "        mlp_masks.append(torch.where(mlp_masks_logits_i > 0., 1., 0.))\n",
    "\n",
    "    masks = (output_mask, attn_q_masks, attn_k_masks, attn_v_masks, mlp_masks)\n",
    "    gpt_graph = GPTGraph()\n",
    "    gpt_graph.set_connections(masks)\n",
    "    gpt_graphs.append(gpt_graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd49229-a431-40f1-a11b-56a02fa2102c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685b1ee3-664a-4eac-a92b-5cd9cb0ff5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16812683-c1f7-46da-a0da-430f0b07dbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4f58a9-5322-4bbc-a24b-6b9208f044d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b7d60cb-50df-417c-b2e4-2236d171189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = (output_mask, attn_q_masks, attn_k_masks, attn_v_masks, mlp_masks)\n",
    "gpt_graph = GPTGraph()\n",
    "gpt_graph.set_connections(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb2fef83-a5cf-4d89-bde9-f7018dce90a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_graph.render_plot(fig_name=f'figures/ioi_{ds_idx}_weight_{n_epoch_w}_edge_{n_epoch_e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb8ff8c0-db92-4347-b12e-6c057b11286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges, nodes = gpt_graph.get_connections('both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bf1450e-ebb7-43ee-9b24-3d3a3a930daf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccb510ff-d549-46ee-a6ec-a6777ce34cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "936ea86e-e303-42ae-8080-64e555035487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{[attn_0_10_O],\n",
       " [attn_0_10_V],\n",
       " [attn_0_11_K],\n",
       " [attn_0_11_O],\n",
       " [attn_0_11_Q],\n",
       " [attn_0_11_V],\n",
       " [attn_0_1_K],\n",
       " [attn_0_1_O],\n",
       " [attn_0_1_Q],\n",
       " [attn_0_1_V],\n",
       " [attn_0_2_K],\n",
       " [attn_0_2_O],\n",
       " [attn_0_2_Q],\n",
       " [attn_0_2_V],\n",
       " [attn_0_3_K],\n",
       " [attn_0_3_O],\n",
       " [attn_0_3_Q],\n",
       " [attn_0_3_V],\n",
       " [attn_0_4_O],\n",
       " [attn_0_4_V],\n",
       " [attn_0_5_O],\n",
       " [attn_0_5_V],\n",
       " [attn_0_7_K],\n",
       " [attn_0_7_O],\n",
       " [attn_0_7_Q],\n",
       " [attn_0_8_K],\n",
       " [attn_0_8_O],\n",
       " [attn_0_8_V],\n",
       " [attn_0_9_K],\n",
       " [attn_0_9_O],\n",
       " [attn_0_9_V],\n",
       " [attn_10_7_K],\n",
       " [attn_10_7_O],\n",
       " [attn_10_7_Q],\n",
       " [attn_10_7_V],\n",
       " [attn_10_8_K],\n",
       " [attn_10_8_O],\n",
       " [attn_10_8_Q],\n",
       " [attn_10_8_V],\n",
       " [attn_11_0_K],\n",
       " [attn_11_0_O],\n",
       " [attn_11_0_Q],\n",
       " [attn_11_0_V],\n",
       " [attn_11_10_K],\n",
       " [attn_11_10_O],\n",
       " [attn_11_10_Q],\n",
       " [attn_11_10_V],\n",
       " [attn_11_3_K],\n",
       " [attn_11_3_O],\n",
       " [attn_11_3_Q],\n",
       " [attn_11_3_V],\n",
       " [attn_11_4_K],\n",
       " [attn_11_4_O],\n",
       " [attn_11_4_V],\n",
       " [attn_11_8_K],\n",
       " [attn_11_8_O],\n",
       " [attn_11_8_Q],\n",
       " [attn_11_8_V],\n",
       " [attn_1_0_K],\n",
       " [attn_1_0_O],\n",
       " [attn_1_0_Q],\n",
       " [attn_1_0_V],\n",
       " [attn_1_10_K],\n",
       " [attn_1_10_O],\n",
       " [attn_1_10_V],\n",
       " [attn_1_11_K],\n",
       " [attn_1_11_O],\n",
       " [attn_1_11_Q],\n",
       " [attn_1_11_V],\n",
       " [attn_1_1_K],\n",
       " [attn_1_1_O],\n",
       " [attn_1_1_Q],\n",
       " [attn_1_1_V],\n",
       " [attn_1_2_K],\n",
       " [attn_1_2_O],\n",
       " [attn_1_2_Q],\n",
       " [attn_1_2_V],\n",
       " [attn_1_3_K],\n",
       " [attn_1_3_O],\n",
       " [attn_1_3_Q],\n",
       " [attn_1_3_V],\n",
       " [attn_1_4_K],\n",
       " [attn_1_4_O],\n",
       " [attn_1_4_Q],\n",
       " [attn_1_4_V],\n",
       " [attn_1_5_K],\n",
       " [attn_1_5_O],\n",
       " [attn_1_5_Q],\n",
       " [attn_1_5_V],\n",
       " [attn_1_6_K],\n",
       " [attn_1_6_O],\n",
       " [attn_1_6_Q],\n",
       " [attn_1_6_V],\n",
       " [attn_1_7_K],\n",
       " [attn_1_7_O],\n",
       " [attn_1_7_Q],\n",
       " [attn_1_7_V],\n",
       " [attn_1_8_K],\n",
       " [attn_1_8_O],\n",
       " [attn_1_8_Q],\n",
       " [attn_1_8_V],\n",
       " [attn_1_9_K],\n",
       " [attn_1_9_O],\n",
       " [attn_1_9_Q],\n",
       " [attn_1_9_V],\n",
       " [attn_2_10_K],\n",
       " [attn_2_10_O],\n",
       " [attn_2_10_V],\n",
       " [attn_2_11_K],\n",
       " [attn_2_11_O],\n",
       " [attn_2_11_Q],\n",
       " [attn_2_11_V],\n",
       " [attn_2_1_K],\n",
       " [attn_2_1_O],\n",
       " [attn_2_1_Q],\n",
       " [attn_2_1_V],\n",
       " [attn_2_4_K],\n",
       " [attn_2_4_O],\n",
       " [attn_2_4_Q],\n",
       " [attn_2_4_V],\n",
       " [attn_2_6_K],\n",
       " [attn_2_6_O],\n",
       " [attn_2_6_Q],\n",
       " [attn_2_6_V],\n",
       " [attn_2_7_K],\n",
       " [attn_2_7_O],\n",
       " [attn_2_7_Q],\n",
       " [attn_2_7_V],\n",
       " [attn_2_8_K],\n",
       " [attn_2_8_O],\n",
       " [attn_2_8_Q],\n",
       " [attn_2_8_V],\n",
       " [attn_2_9_K],\n",
       " [attn_2_9_O],\n",
       " [attn_2_9_Q],\n",
       " [attn_2_9_V],\n",
       " [attn_3_0_K],\n",
       " [attn_3_0_O],\n",
       " [attn_3_0_Q],\n",
       " [attn_3_0_V],\n",
       " [attn_3_10_K],\n",
       " [attn_3_10_O],\n",
       " [attn_3_10_Q],\n",
       " [attn_3_10_V],\n",
       " [attn_3_1_K],\n",
       " [attn_3_1_O],\n",
       " [attn_3_1_Q],\n",
       " [attn_3_1_V],\n",
       " [attn_3_4_K],\n",
       " [attn_3_4_O],\n",
       " [attn_3_4_Q],\n",
       " [attn_3_4_V],\n",
       " [attn_3_5_K],\n",
       " [attn_3_5_O],\n",
       " [attn_3_5_Q],\n",
       " [attn_3_5_V],\n",
       " [attn_3_6_K],\n",
       " [attn_3_6_O],\n",
       " [attn_3_6_Q],\n",
       " [attn_3_6_V],\n",
       " [attn_4_10_K],\n",
       " [attn_4_10_O],\n",
       " [attn_4_10_Q],\n",
       " [attn_4_10_V],\n",
       " [attn_4_3_K],\n",
       " [attn_4_3_O],\n",
       " [attn_4_3_Q],\n",
       " [attn_4_3_V],\n",
       " [attn_4_6_K],\n",
       " [attn_4_6_O],\n",
       " [attn_4_6_Q],\n",
       " [attn_4_6_V],\n",
       " [attn_4_8_K],\n",
       " [attn_4_8_O],\n",
       " [attn_4_8_Q],\n",
       " [attn_4_8_V],\n",
       " [attn_5_0_K],\n",
       " [attn_5_0_O],\n",
       " [attn_5_0_Q],\n",
       " [attn_5_0_V],\n",
       " [attn_5_10_O],\n",
       " [attn_5_10_Q],\n",
       " [attn_5_10_V],\n",
       " [attn_5_3_K],\n",
       " [attn_5_3_O],\n",
       " [attn_5_3_Q],\n",
       " [attn_5_3_V],\n",
       " [attn_5_5_K],\n",
       " [attn_5_5_O],\n",
       " [attn_5_5_Q],\n",
       " [attn_5_5_V],\n",
       " [attn_5_9_K],\n",
       " [attn_5_9_O],\n",
       " [attn_5_9_Q],\n",
       " [attn_5_9_V],\n",
       " [attn_6_6_K],\n",
       " [attn_6_6_O],\n",
       " [attn_6_6_V],\n",
       " [attn_7_6_K],\n",
       " [attn_7_6_O],\n",
       " [attn_7_6_Q],\n",
       " [attn_7_6_V],\n",
       " [attn_8_10_K],\n",
       " [attn_8_10_O],\n",
       " [attn_8_10_Q],\n",
       " [attn_8_10_V],\n",
       " [attn_8_5_K],\n",
       " [attn_8_5_O],\n",
       " [attn_8_5_Q],\n",
       " [input],\n",
       " [mlp_0],\n",
       " [mlp_10],\n",
       " [mlp_11],\n",
       " [mlp_1],\n",
       " [mlp_2],\n",
       " [mlp_3],\n",
       " [mlp_5],\n",
       " [mlp_6],\n",
       " [mlp_7],\n",
       " [mlp_8],\n",
       " [output]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bda1d6-5472-433f-bfe8-0d65e32d7dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
