{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea5c957-aea4-4198-9cb6-b078fab91e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import yaml\n",
    "import torch\n",
    "from os.path import join\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import pickle\n",
    "import transformer_lens\n",
    "from torch.optim import AdamW\n",
    "from os.path import join\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_from_disk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/leiyu/projects/def-yangxu/leiyu/circuit-discovery')\n",
    "from dmc.circuit_gpt import CircuitGPT, CircuitGPTConfig\n",
    "from ioi_dataset import *\n",
    "from ioi_utils import *\n",
    "\n",
    "data_dir = '/home/leiyu/projects/def-yangxu/leiyu/circuit-discovery/data/'\n",
    "results_dir = '/home/leiyu/scratch/circuit-discovery/mask_logits/'\n",
    "mask_dir = '/home/leiyu/scratch/circuit-discovery/mask_logits/'\n",
    "model_dir = '/home/leiyu/projects/def-yangxu/leiyu/LMs/'\n",
    "model_name = 'gpt2-small'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd7b1aea-aeb6-4895-b7b4-694e77e289dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ds_idx, n_epoch_w, n_epoch_e = 0, 0, 66\n",
    "\n",
    "mask_logits_dict_edge = torch.load(\n",
    "    join(mask_dir, f'mask_logits_dict_edge_ioi_{ds_idx}_weight_{n_epoch_w}_edge_{n_epoch_e}.pt')\n",
    ")\n",
    "\n",
    "mask_logits_dict_edge = {k:v.detach().cpu() for k,v in mask_logits_dict_edge.items()}\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "573d2181-328c-48d9-88db-5148f48501dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_ablation(mask_logits_dict_edge, layer_is, head_js):\n",
    "    ablated_mask_logits_dict_edge = {k:torch.clone(v) for k,v in mask_logits_dict_edge.items()}\n",
    "    for layer_i, head_j in zip(layer_is, head_js):\n",
    "        for k in range(layer_i, 12):\n",
    "            mlp_masks_logits_k = ablated_mask_logits_dict_edge[f'blocks.{k}.edge_mask_mlp_logits']\n",
    "            mlp_masks_logits_ki = mlp_masks_logits_k[1:][layer_i*13:(1+layer_i)*13]\n",
    "            mlp_masks_logits_ki[head_j] = -1\n",
    "    \n",
    "            if k > layer_i:\n",
    "                for l in range(12):\n",
    "                    attn_q_masks_logits_kli = ablated_mask_logits_dict_edge[f'blocks.{k}.edge_mask_attention_q_logits'][:,l][1:][layer_i*13:(layer_i+1)*13]\n",
    "                    attn_k_masks_logits_kli = ablated_mask_logits_dict_edge[f'blocks.{k}.edge_mask_attention_k_logits'][:,l][1:][layer_i*13:(layer_i+1)*13]\n",
    "                    attn_v_masks_logits_kli = ablated_mask_logits_dict_edge[f'blocks.{k}.edge_mask_attention_v_logits'][:,l][1:][layer_i*13:(layer_i+1)*13]\n",
    "                    \n",
    "                    # print(attn_q_masks_logits_kli.shape)\n",
    "                    \n",
    "                    attn_q_masks_logits_kli[head_j] = -1.\n",
    "                    attn_k_masks_logits_kli[head_j] = -1.\n",
    "                    attn_v_masks_logits_kli[head_j] = -1.\n",
    "    \n",
    "        ablated_mask_logits_dict_edge['edge_mask_output_logits'][1:][layer_i*13:(1+layer_i)*13][head_j] = -1.\n",
    "            \n",
    "    return ablated_mask_logits_dict_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93b1be7c-08f5-4580-a66b-5d9a8202c7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "083c0187-0992-4852-9277-b4e96c5b3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load IOI data\n",
    "# Note that there are overlaps between train and test sets, due to the way IOIDataset is constructed (randomly sample N items)\n",
    "ioi_prompts = pickle.load(open(join(data_dir, f'ioi_prompts_{ds_idx}.p'), 'rb'))\n",
    "full_model_target_log_probs = torch.load(f'full_model_results/target_log_probs_{ds_idx}.pt')\n",
    "full_model_pred_labels = torch.load(f'full_model_results/pred_labels_{ds_idx}.pt')\n",
    "\n",
    "data_dict = prepare_ioi_data_for_clm(ioi_prompts, full_model_target_log_probs, full_model_pred_labels)\n",
    "ds = IOICircuitDataset(data_dict)\n",
    "dl = DataLoader(\n",
    "    ds,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "457d8507-d59e-4561-bce3-52d091aa2ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. mean pruned model eval accuracy: 0.94,mean eval kl-div: 0.1620,weight density: 1.0000,edge density: 0.0240\n"
     ]
    }
   ],
   "source": [
    "# evaluation before any weight/edge pruning\n",
    "l = 1\n",
    "layer_is = torch.repeat_interleave(torch.arange(l),12)\n",
    "head_js = torch.arange(12).repeat(l)\n",
    "# layer_is = [0]*12 + [1]*12 \n",
    "# head_js = list(range(12)) + list(range(12)) \n",
    "\n",
    "ds_idx, n_epoch_w, n_epoch_e = 0, 0, 66\n",
    "\n",
    "mask_logits_dict_edge = torch.load(\n",
    "    join(mask_dir, f'mask_logits_dict_edge_ioi_{ds_idx}_weight_{n_epoch_w}_edge_{n_epoch_e}.pt')\n",
    ")\n",
    "mask_logits_dict_edge = {k:v.detach().cpu() for k,v in mask_logits_dict_edge.items()}\n",
    "torch.cuda.empty_cache()\n",
    "mask_logits_dict_edge = head_ablation(mask_logits_dict_edge, layer_is, head_js)\n",
    "\n",
    "\n",
    "\n",
    "# circuit_gpt initialization\n",
    "model_path = join(model_dir, model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = torch.device('cuda')    \n",
    "gpt_weights = torch.load(join(model_path, 'model_weights.pt')) \n",
    "circuit_gpt_config = CircuitGPTConfig(\n",
    "    debug=False,\n",
    "    gs_temp_weight=1.0,\n",
    "    gs_temp_edge=1.0,\n",
    "    use_weight_masks=True\n",
    ")\n",
    "circuit_gpt = CircuitGPT(circuit_gpt_config)\n",
    "circuit_gpt.load_pretrained_weight(gpt_weights)\n",
    "# weight_mask_logits = torch.load(join(results_dir, f'mask_logits_dict_weight_ioi_0_weight_257_edge_0.pt'))\n",
    "# weight_mask_logits = {k: v.detach() for k,v in weight_mask_logits.items()}\n",
    "\n",
    "\n",
    "# circuit_gpt.load_pretrained_weight_mask(weight_mask_logits)\n",
    "circuit_gpt.load_pretrained_edge_mask(mask_logits_dict_edge)\n",
    "circuit_gpt.to(device);\n",
    "\n",
    "#################\n",
    "\n",
    "eval_results_full_model = eval_model(circuit_gpt, dl, tokenizer, device, \n",
    "    use_weight_mask=False, use_edge_mask=True, reverse=False\n",
    ")\n",
    "print(\n",
    "    f\"Epoch 0. mean pruned model eval accuracy: {eval_results_full_model['acc']:.2f},\" + \n",
    "    f\"mean eval kl-div: {eval_results_full_model['kl']:.4f},\" + \n",
    "    f\"weight density: {eval_results_full_model['weight_density']:.4f},\" + \n",
    "    f\"edge density: {eval_results_full_model['edge_density']:.4f}\"\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5994e-1ce3-4ac6-872e-d38f49a5bf9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "305ce11b-38e4-4014-966c-8e727814a3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.repeat_interleave(torch.arange(3),12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a29b44b7-6568-44d7-8c05-769c01925aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11,  0,  1,  2,  3,  4,  5,\n",
       "         6,  7,  8,  9, 10, 11,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(12).repeat(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d09440-0664-4c8f-8e82-babe15ca2f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
